{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ee649d-324a-4279-9dff-2fdeb212cd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing producer.py\n"
     ]
    }
   ],
   "source": [
    "%%file producer.py\n",
    "\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from numpy.random import uniform, choice, randn\n",
    "from random import random as r\n",
    "import requests\n",
    "import numpy as np\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "KAFKA_BROKER = 'broker:9092'\n",
    "TRANSACTION_TOPIC = 'gielda'\n",
    "LAG = 1  # Interwał czasu ustawiony na 1 sekundę\n",
    "PROBABILITY_OUTLIER = 0.05\n",
    "\n",
    "\n",
    "api_key = 'pk_c78cf2fb6f324f09a7af5d19a4d43230'\n",
    "\n",
    "\n",
    "\n",
    "def create_producer():\n",
    "    try:\n",
    "        producer = Producer({\n",
    "            \"bootstrap.servers\": KAFKA_BROKER,\n",
    "            \"client.id\": socket.gethostname(),\n",
    "            \"enable.idempotence\": True,\n",
    "            \"batch.size\": 64000,\n",
    "            \"linger.ms\": 10,\n",
    "            \"acks\": \"all\",\n",
    "            \"retries\": 5,\n",
    "            \"delivery.timeout.ms\": 1000\n",
    "        })\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Nie mogę utworzyć producenta\")\n",
    "        producer = None\n",
    "    return producer\n",
    "\n",
    "def get_stock_price(ticker):\n",
    "    url = f'https://cloud.iexapis.com/stable/stock/{ticker}/quote?token={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data['latestPrice']\n",
    "\n",
    "def real_time_quotes(producer, tickers, interval=1):\n",
    "    _id = 0\n",
    "    try:\n",
    "        while True:\n",
    "            records = []\n",
    "            current_time = datetime.utcnow().isoformat()\n",
    "            for ticker in tickers:\n",
    "                price = get_stock_price(ticker)\n",
    "                print(f\"Current price of {ticker}: {price}\")\n",
    "                record = {\n",
    "                    \"id\": _id,\n",
    "                    \"ticker\": ticker,\n",
    "                    \"price\": price,\n",
    "                    \"current_time\": current_time\n",
    "                }\n",
    "                records.append(record)\n",
    "                _id += 1\n",
    "\n",
    "            # Send all records to Kafka\n",
    "            for record in records:\n",
    "                record_json = json.dumps(record).encode(\"utf-8\")\n",
    "                producer.produce(topic=TRANSACTION_TOPIC, value=record_json)\n",
    "            \n",
    "            producer.flush()\n",
    "            print(\"-\" * 40)\n",
    "            time.sleep(interval)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Zakończono pobieranie notowań.\")\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Wystąpił błąd podczas wysyłania notowań.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    producer = create_producer()\n",
    "    if producer is not None:\n",
    "        tickers = [\"AAPL\", \"TSLA\", \"GOOGL\", \"AMZN\", \"MSFT\"]  # Lista pięciu tickerów\n",
    "        interval = LAG#int(input(\"Podaj interwał czasu (w sekundach): \"))\n",
    "        real_time_quotes(producer, tickers, interval)\n",
    "    else:\n",
    "        print(\"Nie udało się utworzyć producenta. Aplikacja zakończona.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8c428-b1cd-4b86-8383-dc2a680e01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opdal w konsoli: python producer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be7b7f7-442c-4256-a17d-d6638a24e322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stream_gielda.py\n"
     ]
    }
   ],
   "source": [
    "%%file stream_gielda.py\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"KafkaStockStream\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    \n",
    "    # Definicja schematu danych JSON\n",
    "    schema = StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"ticker\", StringType(), True),\n",
    "        StructField(\"price\", FloatType(), True),\n",
    "        StructField(\"current_time\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Odczytywanie strumienia danych z Kafki\n",
    "    kafka_df = spark.readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"broker:9092\") \\\n",
    "        .option(\"subscribe\", \"gielda\") \\\n",
    "        .load()\n",
    "    \n",
    "    # Konwersja wartości z formatu bity na string\n",
    "    value_df = kafka_df.selectExpr(\"CAST(value AS STRING) as json\")\n",
    "\n",
    "    # Parsowanie JSON na kolumny\n",
    "    stock_df = value_df.select(from_json(col(\"json\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "    \n",
    "    # Piszemy do konsoli\n",
    "    query = stock_df.writeStream \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .format(\"console\") \\\n",
    "        .start()\n",
    "    \n",
    "    query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22f262-a290-48f0-882a-146ba4ee7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#komenda do pobierania ze strumienia: spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 stream_gielda.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956b2b0-dbc2-4c5b-89f4-f0652e6f5920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac21d4-4467-4ad1-889d-36db85b242fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21b7b0-1748-4a9e-9e5a-736dd2c6b3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
